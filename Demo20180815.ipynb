{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(100)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    y = sess.run(x)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(2)\n",
    "y = tf.constant(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(x+y))\n",
    "    print(sess.run(x-y))\n",
    "    print(sess.run(x*y))\n",
    "    print(sess.run(x/y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.int32)\n",
    "y = tf.placeholder(tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add = tf.add(x,y)\n",
    "sub = tf.subtract(x,y)\n",
    "mul = tf.multiply(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {x:20,y:30}\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(add,feed_dict=d))\n",
    "    print(sess.run(sub,feed_dict=d))\n",
    "    print(sess.run(mul,feed_dict=d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Example With TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-fbc3036e4c69>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_1 = 256 \n",
    "n_hidden_2 = 256 \n",
    "n_input    = 784 \n",
    "n_classes  = 10 \n",
    "n_samples  = mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('inputs'):\n",
    "    x = tf.placeholder(\"float\", [None, n_input], name= 'input_x')\n",
    "    y = tf.placeholder(\"float\", [None, n_classes], name= 'input_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('input_reshape'):\n",
    "    image_input = tf.reshape(x,[-1,28,28,1])\n",
    "    tf.summary.image('input', image_input, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_layer(x, input_tensors, output_tensors, layer_name, activation_function = None):  \n",
    "    with tf.name_scope('Layer'):\n",
    "        with tf.name_scope('Weights'):\n",
    "            weight = tf.Variable(tf.random_normal([input_tensors, output_tensors]), name = 'w')\n",
    "            tf.summary.histogram(name = layer_name + '/Weights', values = weight)\n",
    "        with tf.name_scope('Bias'):\n",
    "            bias = tf.Variable(tf.random_normal([output_tensors]), name= 'b')\n",
    "            tf.summary.histogram(name = layer_name + '/Bias', values = bias)\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            formula = tf.add(tf.matmul(x, weight), bias)\n",
    "        if activation_function is None:\n",
    "            outputs = formula\n",
    "        else:\n",
    "            outputs = activation_function(formula)\n",
    "        tf.summary.histogram(name = layer_name + '/Outputs', values = outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = add_layer(x, input_tensors = n_input, output_tensors = n_hidden_1, layer_name='layer1',activation_function = tf.nn.relu)\n",
    "layer2 = add_layer(layer1, input_tensors = n_hidden_1, output_tensors = n_hidden_2, layer_name='layer2',activation_function = tf.nn.relu)\n",
    "out_layer = add_layer(layer2, input_tensors = n_hidden_2, output_tensors = n_classes, layer_name='out_layer',activation_function = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-3226c314c715>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('cost'):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=out_layer, labels=y))\n",
    "    tf.summary.scalar('loss', cost)\n",
    "    \n",
    "with tf.name_scope('optimizer'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "with tf.name_scope('Accuracy'):\n",
    "    acc = tf.equal(tf.argmax(out_layer, 1), tf.argmax(y, 1))\n",
    "    acc = tf.reduce_mean(tf.cast(acc, tf.float32))\n",
    "    tf.summary.scalar(\"accuracy\", acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost=171.17549170754168\n",
      "Epoch: 2 cost=62.57909491799095\n",
      "Epoch: 3 cost=45.786427470987526\n",
      "Epoch: 4 cost=36.984198188781754\n",
      "Epoch: 5 cost=31.372316499189925\n",
      "Epoch: 6 cost=27.20156055537139\n",
      "Epoch: 7 cost=24.033914830467925\n",
      "Epoch: 8 cost=21.623024080666664\n",
      "Epoch: 9 cost=19.641191550764162\n",
      "Epoch: 10 cost=17.9610248836604\n",
      "Epoch: 11 cost=16.53904706066304\n",
      "Epoch: 12 cost=15.330048905069177\n",
      "Epoch: 13 cost=14.25760362925855\n",
      "Epoch: 14 cost=13.312449820366778\n",
      "Epoch: 15 cost=12.43925337263467\n",
      "Training Completed in 15 Epochs\n"
     ]
    }
   ],
   "source": [
    "merged = tf.summary.merge_all()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    ## Merge Summary\n",
    "    \n",
    "    writer = tf.summary.FileWriter(\"tensorboard2/\", graph = sess.graph)\n",
    "\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.0\n",
    "        total_batch = int(n_samples/batch_size)\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            _, c,result = sess.run([optimizer, cost,merged], feed_dict={x: batch_x, y: batch_y})\n",
    "            avg_cost += c / total_batch\n",
    "            ## Adding summary of each step\n",
    "            writer.add_summary(result,  epoch * total_batch + i)\n",
    "\n",
    "        print(\"Epoch: {} cost={}\".format(epoch+1,avg_cost))\n",
    "\n",
    "    print(\"Training Completed in {} Epochs\".format(training_epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: pyyaml in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from keras)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讀取MNIST 數據"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Activation, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test  = x_test.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test  = x_test.astype('float32')\n",
    "x_train = x_train / 255\n",
    "x_test  = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes  = 10 \n",
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_test  = keras.utils.to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 設定網路參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_1 = 256 \n",
    "n_hidden_2 = 256 \n",
    "n_input    = 784 \n",
    "n_classes  = 10 \n",
    "\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Dense(n_hidden_1, activation='relu', input_shape=(n_input,)))\n",
    "model.add(Dense(n_hidden_2, activation='relu'))\n",
    "model.add(Dense(n_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2885: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 1.0729 - acc: 0.7393 - val_loss: 0.4940 - val_acc: 0.8732\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.4286 - acc: 0.8858 - val_loss: 0.3567 - val_acc: 0.9000\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.3462 - acc: 0.9025 - val_loss: 0.3089 - val_acc: 0.9129\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.3083 - acc: 0.9131 - val_loss: 0.2805 - val_acc: 0.9204\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.2830 - acc: 0.9196 - val_loss: 0.2616 - val_acc: 0.9249\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.2633 - acc: 0.9246 - val_loss: 0.2461 - val_acc: 0.9300\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.2472 - acc: 0.9297 - val_loss: 0.2338 - val_acc: 0.9313\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.2328 - acc: 0.9336 - val_loss: 0.2208 - val_acc: 0.9354\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.2198 - acc: 0.9380 - val_loss: 0.2090 - val_acc: 0.9392\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.2084 - acc: 0.9407 - val_loss: 0.1995 - val_acc: 0.9418\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1980 - acc: 0.9436 - val_loss: 0.1907 - val_acc: 0.9440\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1885 - acc: 0.9466 - val_loss: 0.1838 - val_acc: 0.9466\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1799 - acc: 0.9490 - val_loss: 0.1759 - val_acc: 0.9484\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1718 - acc: 0.9509 - val_loss: 0.1705 - val_acc: 0.9506\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1646 - acc: 0.9538 - val_loss: 0.1632 - val_acc: 0.9511\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=training_epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 預測金融客戶流失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('https://raw.githubusercontent.com/ywchiu/ctbcpy/master/data/Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',\n",
       "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
       "       'IsActiveMember', 'EstimatedSalary', 'Exited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[['CreditScore', 'Geography',\n",
    "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
    "       'IsActiveMember', 'EstimatedSalary']]\n",
    "y = dataset['Exited'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0          1               1        101348.88  \n",
       "1          0               1        112542.58  \n",
       "2          1               0        113931.57  \n",
       "3          0               0         93826.63  \n",
       "4          1               1         79084.10  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male      5457\n",
       "Female    4543\n",
       "Name: Gender, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X['Gender'] = X['Gender'].map(lambda e: 0 if e =='Female' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "France     5014\n",
       "Germany    2509\n",
       "Spain      2477\n",
       "Name: Geography, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Geography'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   France  Germany  Spain\n",
       "0       1        0      0\n",
       "1       0        0      1\n",
       "2       1        0      0\n",
       "3       1        0      0\n",
       "4       0        0      1"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(X['Geography']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X, pd.get_dummies(X['Geography'])], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X['France']\n",
    "del X['Geography']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619       0   42       2       0.00              1          1   \n",
       "1          608       0   41       1   83807.86              1          0   \n",
       "2          502       0   42       8  159660.80              3          1   \n",
       "3          699       0   39       1       0.00              2          0   \n",
       "4          850       0   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Germany  Spain  \n",
       "0               1        101348.88        0      0  \n",
       "1               1        112542.58        0      1  \n",
       "2               0        113931.57        0      0  \n",
       "3               0         93826.63        0      0  \n",
       "4               1         79084.10        0      1  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 11)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 11)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 11)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16958176, -1.09168714, -0.46460796, ...,  1.10643166,\n",
       "        -0.5698444 ,  1.74309049],\n",
       "       [-2.30455945,  0.91601335,  0.30102557, ..., -0.74866447,\n",
       "         1.75486502, -0.57369368],\n",
       "       [-1.19119591, -1.09168714, -0.94312892, ...,  1.48533467,\n",
       "        -0.5698444 , -0.57369368],\n",
       "       ...,\n",
       "       [ 0.9015152 ,  0.91601335, -0.36890377, ...,  1.41231994,\n",
       "        -0.5698444 , -0.57369368],\n",
       "       [-0.62420521, -1.09168714, -0.08179119, ...,  0.84432121,\n",
       "        -0.5698444 ,  1.74309049],\n",
       "       [-0.28401079, -1.09168714,  0.87525072, ...,  0.32472465,\n",
       "         1.75486502, -0.57369368]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.55204276, -1.09168714, -0.36890377, ...,  1.61085707,\n",
       "         1.75486502, -0.57369368],\n",
       "       [-1.31490297, -1.09168714,  0.10961719, ...,  0.49587037,\n",
       "        -0.5698444 , -0.57369368],\n",
       "       [ 0.57162971, -1.09168714,  0.30102557, ..., -0.42478674,\n",
       "        -0.5698444 ,  1.74309049],\n",
       "       ...,\n",
       "       [-0.74791227,  0.91601335, -0.27319958, ...,  0.71888467,\n",
       "        -0.5698444 ,  1.74309049],\n",
       "       [-0.00566991,  0.91601335, -0.46460796, ..., -1.54507805,\n",
       "         1.75486502, -0.57369368],\n",
       "       [-0.79945688,  0.91601335, -0.84742473, ...,  1.61255917,\n",
       "         1.75486502, -0.57369368]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 1s 132us/step - loss: 0.5587 - acc: 0.7954\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 1s 108us/step - loss: 0.5086 - acc: 0.7960\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 0.5062 - acc: 0.7960\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 1s 108us/step - loss: 0.5060 - acc: 0.7960\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 0.5060 - acc: 0.7960\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 1s 114us/step - loss: 0.5060 - acc: 0.7960\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 1s 113us/step - loss: 0.5059 - acc: 0.7960\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 1s 109us/step - loss: 0.5060 - acc: 0.7960\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 0.5060 - acc: 0.7960\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 0.5059 - acc: 0.7960\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 1s 109us/step - loss: 0.5059 - acc: 0.7960\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 1s 112us/step - loss: 0.5059 - acc: 0.7960\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 1s 112us/step - loss: 0.5058 - acc: 0.7960\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.5059 - acc: 0.7960\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 0.5058 - acc: 0.7960\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 0.5057 - acc: 0.7960\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 0.5056 - acc: 0.7960\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.5054 - acc: 0.7960\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 1s 109us/step - loss: 0.5050 - acc: 0.7960\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 0.5042 - acc: 0.7960\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 0.5023 - acc: 0.7960\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.4964 - acc: 0.7960\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 1s 109us/step - loss: 0.4782 - acc: 0.7959\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.4518 - acc: 0.8050\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.4400 - acc: 0.8094\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 0.4355 - acc: 0.8109\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 0.4334 - acc: 0.8106\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.4310 - acc: 0.8124\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.4274 - acc: 0.8119\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 1s 115us/step - loss: 0.4206 - acc: 0.8130\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 0.4086 - acc: 0.8186\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 1s 108us/step - loss: 0.3913 - acc: 0.8305\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.3757 - acc: 0.8429\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 0.3660 - acc: 0.8477\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.3608 - acc: 0.8500 0s - loss: 0.3615 - acc: 0.850\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.3569 - acc: 0.8511\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 1s 113us/step - loss: 0.3544 - acc: 0.8542\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 0.3524 - acc: 0.8555\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 0.3518 - acc: 0.8562\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.3503 - acc: 0.8572\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 1s 112us/step - loss: 0.3498 - acc: 0.8547\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.3487 - acc: 0.8544\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 1s 113us/step - loss: 0.3475 - acc: 0.8596\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 1s 112us/step - loss: 0.3475 - acc: 0.8595\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.3467 - acc: 0.8591\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.3459 - acc: 0.8586\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.3449 - acc: 0.8585\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.3443 - acc: 0.8592\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 0.3439 - acc: 0.8584\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.3436 - acc: 0.8587\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.3425 - acc: 0.8594\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 1s 112us/step - loss: 0.3418 - acc: 0.8582\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.3417 - acc: 0.8607\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 0.3416 - acc: 0.8627\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 0.3408 - acc: 0.8601\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.3410 - acc: 0.8624\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 1s 113us/step - loss: 0.3406 - acc: 0.8616\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 1s 112us/step - loss: 0.3398 - acc: 0.8607\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.3393 - acc: 0.8601\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.3398 - acc: 0.8626\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 1s 109us/step - loss: 0.3398 - acc: 0.8599\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.3390 - acc: 0.8605\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 1s 112us/step - loss: 0.3389 - acc: 0.8610\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.3396 - acc: 0.8594 0s - loss: 0.3406 - acc: 0.8\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.3386 - acc: 0.8604\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 0.3380 - acc: 0.8595\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 0.3382 - acc: 0.8590\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.3376 - acc: 0.8607\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 1s 112us/step - loss: 0.3382 - acc: 0.8611\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.3381 - acc: 0.8591 0s - loss: 0.3420 - acc: 0.\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 1s 113us/step - loss: 0.3374 - acc: 0.8627\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 1s 113us/step - loss: 0.3380 - acc: 0.8610\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.3377 - acc: 0.8596\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 1s 113us/step - loss: 0.3367 - acc: 0.8597\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 1s 112us/step - loss: 0.3376 - acc: 0.8602 0s - loss: 0.3286 - acc: 0. - ETA: 0s - loss: 0.3406 \n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 1s 112us/step - loss: 0.3363 - acc: 0.8612\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 0.3366 - acc: 0.8615\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 1s 112us/step - loss: 0.3366 - acc: 0.8632\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 1s 112us/step - loss: 0.3367 - acc: 0.8632\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 108us/step - loss: 0.3358 - acc: 0.8607\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 1s 105us/step - loss: 0.3369 - acc: 0.8607\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 1s 108us/step - loss: 0.3367 - acc: 0.8621\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 1s 105us/step - loss: 0.3368 - acc: 0.8610\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 1s 107us/step - loss: 0.3362 - acc: 0.8612\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 1s 106us/step - loss: 0.3366 - acc: 0.8596\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 1s 106us/step - loss: 0.3357 - acc: 0.8621\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 1s 109us/step - loss: 0.3359 - acc: 0.8617\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 1s 108us/step - loss: 0.3364 - acc: 0.8616 0s - loss: 0.3351 - acc: 0.86\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 1s 106us/step - loss: 0.3363 - acc: 0.8616\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 1s 106us/step - loss: 0.3357 - acc: 0.8615\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 1s 105us/step - loss: 0.3362 - acc: 0.8604\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 1s 104us/step - loss: 0.3357 - acc: 0.8606\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 1s 105us/step - loss: 0.3357 - acc: 0.8609\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 1s 106us/step - loss: 0.3354 - acc: 0.8615\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 1s 106us/step - loss: 0.3355 - acc: 0.8625\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 1s 107us/step - loss: 0.3355 - acc: 0.8607\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 1s 107us/step - loss: 0.3344 - acc: 0.8621\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 1s 106us/step - loss: 0.3342 - acc: 0.8644\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 1s 105us/step - loss: 0.3354 - acc: 0.8619\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 1s 105us/step - loss: 0.3353 - acc: 0.8617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11ece6c88>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.compile(optimizer = 'sgd', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.55204276, -1.09168714, -0.36890377, ...,  1.61085707,\n",
       "         1.75486502, -0.57369368],\n",
       "       [-1.31490297, -1.09168714,  0.10961719, ...,  0.49587037,\n",
       "        -0.5698444 , -0.57369368],\n",
       "       [ 0.57162971, -1.09168714,  0.30102557, ..., -0.42478674,\n",
       "        -0.5698444 ,  1.74309049],\n",
       "       ...,\n",
       "       [-0.74791227,  0.91601335, -0.27319958, ...,  0.71888467,\n",
       "        -0.5698444 ,  1.74309049],\n",
       "       [-0.00566991,  0.91601335, -0.46460796, ..., -1.54507805,\n",
       "         1.75486502, -0.57369368],\n",
       "       [-0.79945688,  0.91601335, -0.84742473, ...,  1.61255917,\n",
       "         1.75486502, -0.57369368]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2401138 ],\n",
       "       [0.36166686],\n",
       "       [0.12473313],\n",
       "       ...,\n",
       "       [0.17066267],\n",
       "       [0.17364131],\n",
       "       [0.17699295]], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       ...,\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.flatten().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8605"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_pred.flatten().astype(int) == y_test) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1510,   85],\n",
       "       [ 194,  211]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
